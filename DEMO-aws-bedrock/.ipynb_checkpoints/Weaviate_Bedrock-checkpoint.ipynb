{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_hyperlink_cell"
      },
      "source": [
        "[Go to Home Page](https://weaviate.oneblink.ai)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00efd7c2",
      "metadata": {},
      "source": [
        "# Bedrock Model Invocation\n",
        "This notebook contains a Python script to invoke various Bedrock models. The script defines functions to select and interact with different AI models like TITAN, CLAUDE, and others, using the Bedrock API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675cbfb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import boto3\n",
        "import json\n",
        "import requests\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "def get_aws_credentials():\n",
        "    try:\n",
        "        # Attempt to fetch the IAM role name from the EC2 instance metadata\n",
        "        iam_role_url = \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"\n",
        "        response = requests.get(iam_role_url, timeout=1)\n",
        "        response.raise_for_status()\n",
        "        role_name = response.text\n",
        "\n",
        "        # Fetch the credentials associated with the IAM role\n",
        "        credentials_url = iam_role_url + role_name\n",
        "        credentials_response = requests.get(credentials_url, timeout=1)\n",
        "        credentials_response.raise_for_status()\n",
        "        credentials = credentials_response.json()\n",
        "\n",
        "        return {\n",
        "            \"AccessKeyId\": credentials['AccessKeyId'],\n",
        "            \"SecretAccessKey\": credentials['SecretAccessKey'],\n",
        "            \"SessionToken\": credentials.get('Token')  # SessionToken is not always present\n",
        "        }\n",
        "    except requests.RequestException:\n",
        "        # Handle failures (e.g., not running on an EC2 instance, or other network issues)\n",
        "        print(\"Unable to retrieve credentials from EC2 instance metadata.\")\n",
        "        access_key = getpass.getpass(\"Enter AWS Access Key ID: \")\n",
        "        secret_key = getpass.getpass(\"Enter AWS Secret Access Key: \")\n",
        "\n",
        "        return {\n",
        "            \"AccessKeyId\": access_key,\n",
        "            \"SecretAccessKey\": secret_key,\n",
        "            \"SessionToken\": None\n",
        "        }\n",
        "\n",
        "# Use the function\n",
        "credentials = get_aws_credentials()\n",
        "\n",
        "# set environment\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = credentials['AccessKeyId']\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = credentials['SecretAccessKey']\n",
        "if credentials['SessionToken'] is not None:\n",
        "    os.environ['AWS_SESSION_TOKEN'] = credentials['SessionToken']\n",
        "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
        "\n",
        "def invoke_bedrock_model(model_type, template, max_tokens, temperature, top_p, stop_sequences):\n",
        "    \"\"\"\n",
        "    Invoke a Bedrock model based on the given model type and parameters.\n",
        "\n",
        "    Parameters:\n",
        "    - model_type (str): The type of the model (e.g., \"TITAN\", \"CLAUDE\", etc.)\n",
        "    - template (str): The prompt for the model.\n",
        "    - max_tokens (int): Maximum number of tokens to sample.\n",
        "    - temperature (float): Sampling temperature.\n",
        "    - top_p (float): Top-p sampling value.\n",
        "    - stop_sequences (list): List of sequences to stop the sampling.\n",
        "\n",
        "    Returns:\n",
        "    - None: Prints the model's completion.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine the model ID based on the provided model type\n",
        "    if model_type == \"TITAN\":\n",
        "        model_id = \"amazon.titan-tg1-large\"\n",
        "    elif model_type == \"CLAUDE\":\n",
        "        model_id = \"anthropic.claude-v1\"\n",
        "    elif model_type == \"CLAUDE-INSTANT\":\n",
        "        model_id = \"anthropic.claude-instant-v1\"\n",
        "    elif model_type == \"J2\":\n",
        "        model_id = \"ai21.j2-jumbo-instruct\"\n",
        "    else:\n",
        "        # Handle unsupported models\n",
        "        raise Exception(\"Unsupported model\")\n",
        "\n",
        "    # Initialize the Bedrock client\n",
        "    bedrock = boto3.client('bedrock-runtime')\n",
        "\n",
        "    # Prepare the request body with the parameters\n",
        "    body = {\n",
        "        \"prompt\": template,\n",
        "        \"max_tokens_to_sample\": max_tokens,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"stop_sequences\": stop_sequences\n",
        "    }\n",
        "    body_string = json.dumps(body)\n",
        "\n",
        "    # Invoke the Bedrock model and get the response\n",
        "    response = bedrock.invoke_model(\n",
        "        modelId=model_id,\n",
        "        contentType=\"application/json\",\n",
        "        accept=\"application/json\",\n",
        "        body=body_string)\n",
        "\n",
        "    # Parse the response and print the completion\n",
        "    json_obj = json.loads(response.get(\"body\").read().decode())\n",
        "    print(json_obj['completion'])\n",
        "\n",
        "\n",
        "def bedrock_smoke_test():\n",
        "    # Example usage of the invoke_bedrock_model function\n",
        "    model_type=\"CLAUDE-INSTANT\"\n",
        "    prompt = \"What does Weaviate do ? What are the use cases solved by Weaviate ?\"\n",
        "    template = f\"\"\"Human: {prompt}\n",
        "                    Assistant:\"\"\"\n",
        "    max_tokens = 5000\n",
        "    max_tokens=2000\n",
        "    stop_sequences=[]\n",
        "    temperature=0\n",
        "    top_p=0.9\n",
        "    invoke_bedrock_model(model_type, template, max_tokens, temperature, top_p, stop_sequences)\n",
        "\n",
        "\n",
        "# Run the smoke test when the script is executed\n",
        "bedrock_smoke_test()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "344d186a-04c4-4ff0-9eb4-24fd63e58c32",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef0085f-98b6-437e-a01b-8979c71849cc",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_hyperlink_cell"
      },
      "source": [
        "[Go to Home Page](https://weaviate.oneblink.ai)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}